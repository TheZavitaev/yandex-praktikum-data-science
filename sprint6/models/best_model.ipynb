{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбираем лучшую модель\n",
    "\n",
    "Мы обучили дерево решений, случайный лес и линейную регрессию. Какая модель лучше?\n",
    "\n",
    "## Задача\n",
    "\n",
    "Найти модель, у которой на тестовой выборке RMSE не больше 7.5.\n",
    "\n",
    "## Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на обучающую и валидационную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 12345\n",
    "\n",
    "df_train, df_valid = train_test_split(df, test_size=0.25, random_state=random_state)\n",
    "\n",
    "features_train = df_train.drop(['last_price'], axis=1)\n",
    "target_train = df_train['last_price'] / 1_000_000\n",
    "\n",
    "features_valid = df_valid.drop(['last_price'], axis=1)\n",
    "target_valid = df_valid['last_price'] / 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели на обучающей выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE на валидационной выборке: 6.358309353080584\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeRegressor(max_depth=10, random_state=random_state)\n",
    "decision_tree.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = decision_tree.predict(features_valid)\n",
    "\n",
    "mse = mean_squared_error(target_valid, predicted_valid)\n",
    "rmse = mse**0.5\n",
    "\n",
    "print(\"RMSE на валидационной выборке:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 RMSE на валидационной выборке: 8.047334972189107\n",
      "n_estimators = 20 RMSE на валидационной выборке: 7.362362599066984\n",
      "n_estimators = 30 RMSE на валидационной выборке: 7.080032280458895\n",
      "n_estimators = 40 RMSE на валидационной выборке: 7.043174499132039\n",
      "n_estimators = 50 RMSE на валидационной выборке: 7.226618080280562\n"
     ]
    }
   ],
   "source": [
    "for estim in range(10, 51, 10):\n",
    "    random_forest = RandomForestRegressor(n_estimators=estim, max_depth=10, random_state=random_state)\n",
    "    random_forest.fit(features_train, target_train)\n",
    "    predicted_valid = random_forest.predict(features_valid)\n",
    "    \n",
    "    mse = mean_squared_error(target_valid, predicted_valid)\n",
    "    rmse = mse**0.5\n",
    "\n",
    "    print(\"n_estimators =\", estim, \"RMSE на валидационной выборке:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE на валидационной выборке: 7.726006697008546\n"
     ]
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid = linear_regression.predict(features_valid)\n",
    "\n",
    "mse = mean_squared_error(target_valid, predicted_valid)\n",
    "rmse = mse**0.5\n",
    "\n",
    "print(\"RMSE на валидационной выборке:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из значений корня из среднеквадратичной ошибки (RMSE) выберем в качестве целевой модели **случайный лес в регрессии** с максимальной глубиной равной `10` и количеством деревьем равным `40`. Обучим ее на исходном датасете: чем больше данных, тем лучше результат. Валидационная выборка не нужна: вы уже определились с лучшей моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['last_price'], axis=1)\n",
    "target = df['last_price'] / 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=40,\n",
       "                      n_jobs=None, oob_score=False, random_state=12345,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RandomForestRegressor(n_estimators=40, max_depth=10, random_state=random_state)\n",
    "best_model.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE на исходном датасете: 3.4288390710078853\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(features)\n",
    "\n",
    "mse = mean_squared_error(target, predictions)\n",
    "rmse = mse**0.5\n",
    "\n",
    "print(\"RMSE на исходном датасете:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_model, 'best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE:\n",
    "\n",
    "* Обучающая выборка: 3.4288390710078853\n",
    "* Тестовая выборка: 7.005512842543898"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему победила модель именно с такими гиперпараметрами? Вопрос, конечно же, интересный! Ответа на него нет. Иногда нужно просто перебирать разные варианты, смотреть на результаты, а потом взять — и выбрать лучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
